---
title: 'Gaussian Processes for Time Series Modelling'
author:
  - name: 'Azar Raphaela'
  - name: 'Gumede Sbonelo'
date: today
format: beamer
---

```{r Setup}
#| echo: FALSE
#| include: FALSE

packs = c('dplyr', 'forecast', 'fpp2', 'ggfortify', 'ggplot2', 'knitr', 
			 'splines', 'rstan')

for(pack in packs){
	if(!requireNamespace(pack, quietly=TRUE)){
		install.packages(pack, quiet=TRUE)
	}
	library(pack, character.only=TRUE)
}
```

## Dataset

```{r EDA}
#| echo: FALSE

df <- EuStockMarkets[, 'FTSE'] # Load data

p <- autoplot(df) +
	labs(title='Daily Closing Prices of FTSE (1991-1998)',
		  x='Time',
		  y='FTSE') + 
	theme_minimal()
p # Display plot
```

## CMA(k = 365)

```{r CMA}
#| echo: FALSE

p + autolayer(ma(df,365), series='MA365', size=2, color='firebrick')
```

## Discussion

There are infinite models that we could use. However, since we picked up the trend using CMA(k=365) we can make an inspired guess. A second degree polynomial spline seems to be appropriate.

Let us divide the data into a train and test set in order to compare model performance.

## Partition

```{r Partition}
#| echo: FALSE

n <- length(df) # Number of observations in the data
train_end_index <- floor(0.7 * n) # (70/30)% split of the data

train <- window(df, end = time(df)[train_end_index]) # Training data
test <- window(df, start = time(df)[train_end_index + 1]) # Testing data

# Plot the train vs test set
autoplot(df) +
	autolayer(train, color = 'lightskyblue', size = 2, series = 'Train') +
	autolayer(test, color = 'darkorange', size = 2, series = 'Test') +
	labs(title='Daily Closing Prices of FTSE (1991-1998)',
		  x='Time',
		  y='FTSE') + 
	theme_minimal()
```

## B-Spline

### Base Case

$$
B_{i, 0}(t) := 
\begin{cases} 
	1, & \text{if } t_{i} \leq t < t_{i+1} \\
	0, & \text{otherwise}
\end{cases}
$$

### Recursive Step

$$
B_{i,p}(t) := 
\frac{t - t_{i}}{t_{i+p} - t_{i}} B_{i, p-1}(t) 
+ \frac{t_{i+p+1}-t}{t_{i+p+1}-t_{i+1}} B_{i+1, p-1}(t)
$$

#### Where

$t$ is the covariate and $p$ is the degree of the polynomial.

## Spline

```{r Spline}
#| echo: FALSE

train_time <- as.numeric(time(train)) # Extract the time component for training data
test_time <- as.numeric(time(test)) # Extract the time component for testing data

fit <- lm(train ~ bs(train_time, df = 2)) # Fit a spline model of degree 2

train_preds <- predict(fit, newdata=data.frame(train_time=train_time)) # Spline on training data
test_preds <- predict(fit, newdata=data.frame(train_time=test_time)) # Extrapolate

train_ts <- ts(train_preds, start=start(train), frequency=frequency(train)) # Convert to ts
test_ts <- ts(test_preds, start=start(test), frequency=frequency(test)) # Convert to ts

autoplot(df) +
	autolayer(train_ts, color='lightskyblue', size=2, series='Train Spline') +
	autolayer(test_ts, color='darkorange', size=2, series='Test Spline') +
	labs(title='Daily Closing Prices of FTSE (1991-1998)',
		  x='Time',
		  y='FTSE') + 
	theme_minimal()
```

## Discussion

### Problem

Robust use of the polynomial model requires knowledge of how the coefficients interact to control functional behaviour, 
which becomes unmanageable as the order of the polynomial grows.

### Solution

A Gaussian Process defines a probability distribution over functions; 
in other words, it is an entire function from the covariate space to the real-valued output space.

## Gaussian Process

```{r GP}
#| echo: FALSE
#| warning: FALSE

rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
parallel:::setDefaultClusterOptions(setup_strategy='sequential')

util <- new.env()

par(family='serif', las=1, bty='l', cex.axis=1, cex.lab=1,
	 cex.main=1, xaxs='i', yaxs='i', mar=c(5, 5, 3, 5))

# Gram grid
x <- 22 * (0:(n-1)) / (n-1) - 11

# Parameters that specify our GP
alpha_true <- 3
rho_true <- 5.5

# Pack everything together
simu_data <- list(alpha=alpha_true, rho=rho_true, N=n, x=x)

# Sample from the MVN(0, Gram-matrix)
simu_fit <- stan(file='stan_programs/presentation.stan', 
					  data=simu_data, warmup=0, iter=4000, chains=1, 
					  seed=494838, algorithm='Fixed_param', refresh=0, 
					  verbose=FALSE)

# Visualization code
source('gp_utility.R', local=util)

util$plot_gp_prior_realizations(simu_fit, x, 'Realizations')

```
