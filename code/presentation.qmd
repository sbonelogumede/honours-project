---
title: 'Gaussian Processes for Time Series Modelling'
author:
  - 'Azar Raphaela'
  - 'Gumede Sbonelo'
institute:  
  - 'University of Cape Town'
  - 'Supervisor: Dr. Birgit Erni'
date: today
format: 
  revealjs:
    incremental: true
    transition: fade
    css: css/styles.css
---

```{r Setup}
#| echo: FALSE
#| include: FALSE
#| warning: FALSE

options(repos=c(CRAN='https://cloud.r-project.org'))

packs <- c('dplyr', 'forecast', 'fpp2', 'ggfortify', 'gifski', 'ggplot2', 'knitr', 
			  'splines', 'rstan')

for(pack in packs){
	if(!requireNamespace(pack, quietly=TRUE)){
		install.packages(pack, quiet=TRUE)
	}
	library(pack, character.only=TRUE)
}

colors <- c('skyblue', 'seagreen', 'pink', 'cyan', 'gray', 'salmon', 'steelblue')
```

## Plot of the dataset

```{r EDA}
#| echo: FALSE
#| warning: FALSE

df <- EuStockMarkets[, 'FTSE'] # Load data

autoplot(df) +
	labs(title='Daily Closing Prices of FTSE (1991-1998)',
		  x='Time',
		  y='FTSE') + 
	theme_minimal()
```

```{r Partition}
#| echo: FALSE
#| warning: FALSE

n <- length(df) # Number of observations in the data
train_end_index <- floor(0.7 * n) # (70/30)% split of the data

train <- window(df, end = time(df)[train_end_index]) # Training data
test <- window(df, start = time(df)[train_end_index + 1]) # Testing data
train_time <- as.numeric(time(train)) # Extract the time component for training data
test_time <- as.numeric(time(test)) # Extract the time component for testing data
```

## Linear model

### Definition

A linear model refers to any model which assumes linearity in the system.

### Population model

$$
\mathbf{y} = 
\mathbf{X} \boldsymbol{\beta} + \mathbf{e}, \quad 
\text{where} \quad
\mathbf{e} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}_{n}\sigma^2)
$$

### Fitted model

$$\hat{\mathbf{y}} = \mathbf{X} \hat{\boldsymbol{\beta}}$$

## Linear model plot

```{r Linear-Model}
#| echo: FALSE
#| eval: TRUE
#| include: TRUE
#| warning: FALSE

linear_model <- lm(train ~ train_time)
	train_preds <- predict(linear_model, newdata=data.frame(train_time=train_time)) # Spline on training data
	test_preds <- predict(linear_model, newdata=data.frame(train_time=test_time)) # Extrapolate
	train_ts <- ts(train_preds, start=start(train), frequency=frequency(train)) # Convert to ts
	test_ts <- ts(test_preds, start=start(test), frequency=frequency(test))
	
	p <- autoplot(df) +
		autolayer(train_ts, series='Train Linear Model', size=1.5) +
		autolayer(test_ts, series='Test Linear Model', size=1.5) +
		scale_color_manual(values=c('Train Linear Model'='lightskyblue', 
											 'Test Linear Model'='darkorange')) +
		labs(title='Daily Closing Prices of FTSE (1991-1998)',
			  x='Time',
			  y='FTSE',
			  color='Legend') + 
		theme_minimal() +
		theme(legend.text = element_text(size = 14), 
				legend.title = element_text(size = 16))
	print(p)
```

## Discussion

### Problem

Linear models are not flexible enough to capture the non-linearity of the data.

### Solution

Try using non-linear models such as polynomial regression or B-splines.

## B-spline

### Definition

A B-spline is a piecewise polynomial of order n.

### Base case

$$
B_{i, 0}(t) := 
\begin{cases} 
	1, & \text{if } t_{i} \leq t < t_{i+1} \\
	0, & \text{otherwise}
\end{cases}
$$

### Recursive step

$$
B_{i,p}(t) := 
\frac{t - t_{i}}{t_{i+p} - t_{i}} B_{i, p-1}(t) 
+ \frac{t_{i+p+1}-t}{t_{i+p+1}-t_{i+1}} B_{i+1, p-1}(t)
$$
$$\text{where,} \; t \; \text{is the covariate and} \; p \; \text{is the degree of the polynomial.}$$

```{r Spline-model}
color_values <- c()

for(dof in 2:8){
	# Fit a spline model
	spline_model <- lm(train ~ bs(train_time, df=dof))
	
	# Make predictions
	train_preds <- predict(spline_model, newdata=data.frame(train_time=train_time))
	test_preds <- predict(spline_model, newdata=data.frame(train_time=test_time))
	
	# Convert to time series
	train_ts <- ts(train_preds, start=start(train), frequency=frequency(train))
	test_ts <- ts(test_preds, start=start(test), frequency=frequency(test))
	
	# Create series name
	train_name <- paste0('Train Spline df=', dof)
	test_name <- paste0('Test Spline df=', dof)
	
	# Add layers to the plot
	p <- p + 
		autolayer(train_ts, series=train_name, size=1.2) +
		autolayer(test_ts, series=test_name, size=1.2)
	
	# Assign colors to the named vector
	color_idx <- (dof-1) %% length(colors) + 1
	color_values[train_name] <- paste0('light', colors[color_idx])
	color_values[test_name] <- paste0(colors[color_idx])
}

# Add a custom color scale - using the first two colors for each df value
p <- p + scale_color_manual(values=color_values)

# Display the final plot
print(p)
```

## Discussion

### Problem

Splines do not consider the correlations between data points. 
They model the immediate shape of the data.

### Solution

Use Gaussian processes to model the data generating process. 
GPs consider all the observations and their correlations.

## Gaussian process

### Definition

A time continuous stochastic process $\{X_{t}; \ t \in T\}$ is Gaussian 
if and only if for every finite set of indices $t_{1},...,t_{k}$ in the index set $T$
$$\mathbf{X}_{t_{1},...,t_{k}} = (X_{t_{1}},...,X_{t_{k}})$$
is a multivariate Gaussian random variable.

### Meaning

$$f \sim GP(m, k) \rightarrow f_{n} \sim MVN(\mathbf{m}, \mathbf{K})$$
$$\pi(y_{n};f(x_{n}),\phi) \rightarrow \pi(y_{n}; f_{n}, \phi)$$

## Mean Vector

$$
\mathbf{m} =
\begin{bmatrix}
\mu(x_{1}^{\text{obs}}) \\
\vdots \\
\mu(x_{N_{\text{obs}}}^{\text{obs}})  \\
\mu(x_{1}^{\text{pred}})\\
\vdots \\
\mu(x_{N_{\text{pred}}}^{\text{pred}})
\end{bmatrix}
$$

## Covariance-Matrix

$$
\mathbf{K} = 
\begin{bmatrix}
k(x_{1}^{\text{obs}}, x_{1}^{\text{obs}}) & \cdots & k(x_{1}^{\text{obs}}, x_{N_{\text{obs}}}^{\text{obs}}) & \quad & k(x_{1}^{\text{obs}}, x_{1}^{\text{pred}}) & \cdots & k(x_{1}^{\text{obs}}, x_{N_{\text{pred}}}^{\text{pred}}) \\
\vdots & \ddots & \vdots & & \vdots & \ddots & \vdots \\
k(x_{N_{\text{obs}}}^{\text{obs}}, x_{1}^{\text{obs}}) & \cdots & k(x_{N_{\text{obs}}}^{\text{obs}}, x_{N_{\text{obs}}}^{\text{obs}}) & \quad & k(x_{N_{\text{obs}}}^{\text{obs}}, x_{1}^{\text{pred}}) & \cdots & k(x_{N_{\text{obs}}}^{\text{obs}}, x_{N_{\text{pred}}}^{\text{pred}}) \\
k(x_{1}^{\text{pred}}, x_{1}^{\text{obs}}) & \cdots & k(x_{1}^{\text{pred}}, x_{N_{\text{obs}}}^{\text{obs}}) & \quad & k(x_{1}^{\text{pred}}, x_{1}^{\text{pred}}) & \cdots & k(x_{1}^{\text{pred}}, x_{N_{\text{pred}}}^{\text{pred}}) \\
\vdots & \ddots & \vdots & & \vdots & \ddots & \vdots \\
k(x_{N_{\text{pred}}}^{\text{pred}}, x_{1}^{\text{obs}}) & \cdots & k(x_{N_{\text{pred}}}^{\text{pred}}, x_{N_{\text{obs}}}^{\text{obs}}) & \quad & k(x_{N_{\text{pred}}}^{\text{pred}}, x_{1}^{\text{pred}}) & \cdots & k(x_{N_{\text{pred}}}^{\text{pred}}, x_{N_{\text{pred}}}^{\text{pred}})
\end{bmatrix}
$$

```{r GP}
#| echo: FALSE
#| eval: TRUE
#| include: FALSE
#| warning: FALSE

rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
parallel:::setDefaultClusterOptions(setup_strategy='sequential')

util <- new.env()

par(family='serif', las=1, bty='l', cex.axis=1, cex.lab=1,
	 cex.main=1, xaxs='i', yaxs='i', mar=c(5, 5, 3, 5))

# Gram grid
x <- 22 * (0:(n-1)) / (n-1) - 11

# Parameters that specify our GP
alpha_true <- 3
rho_true <- 5.5
sigma_true <- 2

# Pack everything together
simu_data <- list(alpha=alpha_true, rho=rho_true, sigma=sigma_true, 
						N=n, x=x)

# Sample from the MVN(0, Gram-matrix)
simu_fit <- stan(file='stan_programs/presentation.stan', 
					  data=simu_data, warmup=0, iter=4000, chains=1, 
					  seed=494838, algorithm='Fixed_param', refresh=0, 
					  verbose=FALSE)

# Visualization code
source('gp_utility.R', local=util)

# Save util and simu_fit for later
# saveRDS(util, file='../objects/util_env.rds')
# saveRDS(simu_fit, file='../objects/simu_fit.rds')
# saveRDS(x, file='../objects/x.rds')
```

## Prior realizations

```{r PR}
#| echo: FALSE
#| eval: TRUE
#| include: TRUE
#| warning: FALSE

# util <- readRDS('../objects/util_env.rds')
# simu_fit <- readRDS('../objects/simu_fit.rds')
# x <- readRDS('../objects/x.rds')
# source('gp_utility.R', local=util)

util$plot_gp_prior_realizations(simu_fit, x, 'Prior realizations')
```

## Prior quantiles

```{r PQ}
#| echo: FALSE
#| eval: TRUE
#| include: TRUE
#| warning: FALSE

util$plot_gp_prior_quantiles(simu_fit, x, 'Prior quantiles')
```
