---
title: "Presentation"
format: beamer
header-includes:
  - \usepackage{xcolor}
  - \definecolor{steelblue}{RGB}{70,130,180}  # define steelblue
  - \setbeamercolor{frametitle}{fg=steelblue}
  - \setbeamertemplate{frametitle}[default][center]
  - \setlength{\topsep}{0pt}      # general top spacing
  - \setlength{\partopsep}{0pt}    # extra top spacing in lists
  - \setlength{\abovedisplayskip}{5pt} # equations
  - \addtobeamertemplate{frametitle}{}{\vspace{-1em}}  # Reduce space after frame title
  - \setlength{\parskip}{0pt}                     # Remove paragraph spacing
  - \setlength{\itemsep}{0pt}                     # Reduce item spacing in lists
  - \setbeamertemplate{itemize/enumerate body begin}{\vspace{-0.5em}}  # Lists closer to headings
  - \setbeamertemplate{block begin}{\vskip-0.5ex}      # Reduce block spacing
  - \usepackage{titlesec}
  - \titlespacing{\section}{0pt}{1ex plus .1ex minus .2ex}{1ex plus .2ex}
  - \titlespacing{\subsection}{0pt}{1ex plus .1ex minus .2ex}{1ex plus .2ex}
  - \titlespacing{\subsubsection}{0pt}{1ex plus .1ex minus .2ex}{1ex plus .2ex}
---

---

# Application

`OBJECTIVE`: Forecasting the levels of air pollution for the TableView station in Cape Town.

`RESPONSE`: Nitrogen dioxide

`COVARIATES`: Particulate matter, Sulfur dioxide, and Wind speed

---

# Time series plot

![Time series of $X_{t}$](time-series.png)

---

# Components of the time series

`TREND COMPONENT`: Using the `ndiffs()` function in the `forecast` package,
we obtain $1$, suggesting that there is a linear trend in the time series.

`SEASONAL COMPONENT`: Using the `nsdiffs()` function in the `forecast` package,
we obtain $0$, suggesting that no seasonality is present in the time series.

`CYCLICAL COMPONENT`: There is no clear indication of a cyclical component in the time series.

`RANDOM COMPONENT`: Random variation is present in the time series.

---

# Heteroscedasticity

$$X_{t} \not\sim \mathcal{N}(\mu, \, \sigma^2).$$

Using the `BoxCox.lambda()` function in the `forecast` package,
we get that $\lambda \approx 0$, suggesting a natural log transformation.

$$\text{Let} \, Y_{t} = \text{ln}(X_{t}),$$

$$Y_{t} \overset{approx}{\sim} \mathcal{N}(\mu, \, \sigma^2).$$

---

# Fitted models

`AVERAGE`: The prediction is the average value.

`NAIVE`: The prediction is the last observed value.

`DRIFT`: The prediction is the last observed value adjusted for the average trend.

`AR(1)`: The prediction is based on a constant, plus a fraction of the previous value.

# Gaussian process models

$$f_{1}(x) \sim \text{GP}(0, \, \sigma^2\delta_{ij}), \, \delta_{ij} = 1 \, \text{for} \, i=j, \, \text{and} \, \delta_{ij} = 0 \, \text{for} \, i \neq j.$$
$$f_{2}(x) \sim \text{GP}(\mathbf{X}\boldsymbol{\beta}, \, \sigma^2\delta_{ij}), \, \delta_{ij} = 1 \, \text{for} \, i=j, \, \text{and} \, \delta_{ij} = 0 \, \text{for} \, i \neq j.$$
$$f_{3}(x) \sim \text{GP}(0, \, \alpha^2\text{exp}[(\frac{x_{i} - x_{j}}{\rho})^2]).$$
$$f_{4}(x) \sim \text{GP}(\mathbf{X}\boldsymbol{\beta}, \, \alpha^2\text{exp}[(\frac{x_{i} - x_{j}}{\rho})^2]).$$

---

# Results

![OOS performance of the fitted models.](results.png)


