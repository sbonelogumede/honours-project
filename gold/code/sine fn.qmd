---
title: "Sine fn (python version) "
format: html
editor: visual
---

```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, DotProduct, WhiteKernel, ConstantKernel

# ---------- 1) Simulate sine with AUTOCORRELATED + HETEROSCEDASTIC noise ----------
rng = np.random.default_rng(7)
n_train = 140
X_train = np.linspace(0, 6, n_train).reshape(-1, 1)
x = X_train.ravel()

# True signal
f_true = np.sin(x)

# Heteroscedastic noise scale (varies with x)
sigma_x = 0.10 + 0.15*(x/6) + 0.10*np.maximum(0, np.sin(0.7*x))  # always positive

# AR(1) autocorrelated noise with coefficient phi
phi = 0.6
eps = np.zeros_like(x)
eta = rng.normal(0.0, 1.0, size=n_train)
for t in range(1, n_train):
    eps[t] = phi * eps[t-1] + eta[t] * sigma_x[t]  # correlated noise with varying scale
y_train = f_true + eps  # observed

# Test grid for prediction/forecast
X_test = np.linspace(0, 10, 500).reshape(-1, 1)
x_test = X_test.ravel()
f_true_test = np.sin(x_test)

# ---------- 2) Helper: fit & plot with a given SIGNAL kernel + correlated "noise GP" ----------
BLUE = "#1f77b4"
LIGHT_BLUE = "#9ecae1"

def fit_and_plot(signal_kernel, title, outpath):
    # Correlated noise component (short length-scale RBF)
    noise_kernel = ConstantKernel(0.3, (1e-3, 10.0)) * RBF(length_scale=0.25, length_scale_bounds=(1e-2, 1.0))
    # Small iid nugget on top (learned)
    white = WhiteKernel(noise_level=1e-4, noise_level_bounds=(1e-6, 1e-1))
    kernel = signal_kernel + noise_kernel + white

    # Heteroscedastic GP: pass per-point variances via alpha (approximation)
    gp = GaussianProcessRegressor(
        kernel=kernel,
        alpha=sigma_x**2,      # input-dependent noise variance
        normalize_y=True,
        n_restarts_optimizer=1,
        random_state=0
    )
    gp.fit(X_train, y_train)
    y_mean, y_std = gp.predict(X_test, return_std=True)

    # Plot
    plt.figure(figsize=(11, 6))
    # observations
    plt.plot(x, y_train, 'k.', markersize=3, label="Observed")
    # GP posterior
    plt.plot(x_test, y_mean, '-', color=BLUE, linewidth=2, label="GP mean")
    plt.fill_between(x_test, y_mean - 2*y_std, y_mean + 2*y_std, color=LIGHT_BLUE, alpha=0.35, label="95% CI")
    # (optional) true function for reference
    plt.plot(x_test, f_true_test, 'k--', linewidth=1, alpha=0.6, label="True sine")

    plt.title(title)
    plt.xlabel("x (input)")
    plt.ylabel("y (output)")
    plt.legend(loc="best")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(outpath, dpi=180)
    plt.show()

    return gp

# ---------- 3) Fit three GP variants with correlated + heteroscedastic noise ----------
# (a) RBF signal
gp_rbf_noise = fit_and_plot(ConstantKernel(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2)),
                            "GP (RBF signal) + Correlated & Heteroscedastic Noise",
                            "/mnt/data/gp_rbf_corr_het.png")

# (b) Periodic signal
gp_per_noise = fit_and_plot(ConstantKernel(1.0, (1e-3, 1e3)) *
                            ExpSineSquared(length_scale=1.0, periodicity=2*np.pi,
                                           length_scale_bounds=(1e-2, 1e2), periodicity_bounds=(4.0, 8.0)),
                            "GP (Periodic signal) + Correlated & Heteroscedastic Noise",
                            "/mnt/data/gp_periodic_corr_het.png")

# (c) Linear signal
gp_lin_noise = fit_and_plot(ConstantKernel(1.0, (1e-3, 1e3)) * DotProduct(sigma_0=1.0),
                            "GP (Linear signal) + Correlated & Heteroscedastic Noise",
                            "/mnt/data/gp_linear_corr_het.png")

# Also show the noise scale used
plt.figure(figsize=(10,3))
plt.plot(x, sigma_x, color="gray")
plt.title("Input-dependent noise scale σ(x) used to simulate heteroscedasticity")
plt.xlabel("x (input)")
plt.ylabel("σ(x)")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("/mnt/data/noise_scale_sigma_x.png", dpi=180)
plt.show()

# Print learned kernels (for reference)
kernels = {
    "RBF + noise": str(gp_rbf_noise.kernel_),
    "Periodic + noise": str(gp_per_noise.kernel_),
    "Linear + noise": str(gp_lin_noise.kernel_),
}
kernels

```

```{python}
# Continue: finish the periodic model plot only (quick re-create essentials)
import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import ExpSineSquared, RBF, DotProduct, WhiteKernel, ConstantKernel

# Recreate data & helpers (fast)
rng = np.random.default_rng(7)
n_train = 140
x = np.linspace(0, 6, n_train)
X_train = x.reshape(-1,1)
f_true = np.sin(x)
sigma_x = 0.10 + 0.15*(x/6) + 0.10*np.maximum(0, np.sin(0.7*x))
phi = 0.6
eps = np.zeros_like(x)
eta = rng.normal(0.0, 1.0, size=n_train)
for t in range(1, n_train):
    eps[t] = phi*eps[t-1] + eta[t]*sigma_x[t]
y_train = f_true + eps
X_test = np.linspace(0, 10, 500).reshape(-1,1)
x_test = X_test.ravel()
f_true_test = np.sin(x_test)

def fit_and_plot(signal_kernel, title, outpath):
    BLUE = "#1f77b4"; LIGHT_BLUE="#9ecae1"
    noise_kernel = ConstantKernel(0.3, (1e-3, 10.0)) * RBF(length_scale=0.25, length_scale_bounds=(1e-2, 1.0))
    white = WhiteKernel(noise_level=1e-4, noise_level_bounds=(1e-6, 1e-1))
    kernel = signal_kernel + noise_kernel + white
    gp = GaussianProcessRegressor(kernel=kernel, alpha=sigma_x**2, normalize_y=True,
                                  n_restarts_optimizer=1, random_state=0)
    gp.fit(X_train, y_train)
    y_mean, y_std = gp.predict(X_test, return_std=True)
    plt.figure(figsize=(11,6))
    plt.plot(x, y_train, 'k.', markersize=3, label="Observed")
    plt.plot(x_test, y_mean, '-', color=BLUE, linewidth=2, label="GP mean")
    plt.fill_between(x_test, y_mean-2*y_std, y_mean+2*y_std, color=LIGHT_BLUE, alpha=0.35, label="95% CI")
    plt.plot(x_test, f_true_test, 'k--', linewidth=1, alpha=0.6, label="True sine")
    plt.title(title); plt.xlabel("x (input)"); plt.ylabel("y (output)"); plt.legend(); plt.grid(True, alpha=0.3)
    plt.tight_layout(); plt.savefig(outpath, dpi=180); plt.show()
    return gp

gp_per_noise = fit_and_plot(ConstantKernel(1.0, (1e-3, 1e3)) *
                            ExpSineSquared(length_scale=1.0, periodicity=2*np.pi,
                                           length_scale_bounds=(1e-2, 1e2), periodicity_bounds=(4.0, 8.0)),
                            "GP (Periodic signal) + Correlated & Heteroscedastic Noise",
                            "/mnt/data/gp_periodic_corr_het.png")

```

```{python}
# Try faster runs (no restarts) for periodic and linear versions

import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, DotProduct, WhiteKernel, ConstantKernel

# Recreate minimal data quickly
rng = np.random.default_rng(7)
n_train = 110
x = np.linspace(0, 6, n_train)
X_train = x.reshape(-1,1)
f_true = np.sin(x)
sigma_x = 0.10 + 0.15*(x/6) + 0.10*np.maximum(0, np.sin(0.7*x))
phi = 0.6
eps = np.zeros_like(x)
eta = rng.normal(0.0, 1.0, size=n_train)
for t in range(1, n_train):
    eps[t] = phi*eps[t-1] + eta[t]*sigma_x[t]
y_train = f_true + eps

X_test = np.linspace(0, 10, 350).reshape(-1,1)
x_test = X_test.ravel()
f_true_test = np.sin(x_test)

BLUE = "#1f77b4"; LIGHT_BLUE="#9ecae1"

def fit_and_plot(signal_kernel, title, outpath):
    noise_kernel = ConstantKernel(0.3, (1e-3, 10.0)) * RBF(length_scale=0.25, length_scale_bounds=(1e-2, 1.0))
    white = WhiteKernel(noise_level=1e-4, noise_level_bounds=(1e-6, 1e-1))
    kernel = signal_kernel + noise_kernel + white
    gp = GaussianProcessRegressor(kernel=kernel, alpha=sigma_x**2, normalize_y=True,
                                  n_restarts_optimizer=0, random_state=0)
    gp.fit(X_train, y_train)
    y_mean, y_std = gp.predict(X_test, return_std=True)
    plt.figure(figsize=(11,6))
    plt.plot(x, y_train, 'k.', markersize=3, label="Observed")
    plt.plot(x_test, y_mean, '-', color=BLUE, linewidth=2, label="GP mean")
    plt.fill_between(x_test, y_mean-2*y_std, y_mean+2*y_std, color=LIGHT_BLUE, alpha=0.35, label="95% CI")
    plt.plot(x_test, f_true_test, 'k--', linewidth=1, alpha=0.6, label="True sine")
    plt.title(title); plt.xlabel("x (input)"); plt.ylabel("y (output)"); plt.legend(); plt.grid(True, alpha=0.3)
    plt.tight_layout(); plt.savefig(outpath, dpi=180); plt.show()

# Periodic
fit_and_plot(ConstantKernel(1.0, (1e-3, 1e3)) *
             ExpSineSquared(length_scale=1.0, periodicity=2*np.pi,
                            length_scale_bounds=(1e-2, 1e2), periodicity_bounds=(4.0, 8.0)),
             "GP (Periodic signal) + Correlated & Heteroscedastic Noise",
             "/mnt/data/gp_periodic_corr_het.png")

# Linear
fit_and_plot(ConstantKernel(1.0, (1e-3, 1e3)) * DotProduct(sigma_0=1.0),
             "GP (Linear signal) + Correlated & Heteroscedastic Noise",
             "/mnt/data/gp_linear_corr_het.png")

# Noise scale plot
plt.figure(figsize=(10,3))
plt.plot(x, sigma_x, color="gray")
plt.title("Input-dependent noise scale σ(x) used to simulate heteroscedasticity")
plt.xlabel("x (input)"); plt.ylabel("σ(x)")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("/mnt/data/noise_scale_sigma_x.png", dpi=180)
plt.show()

```
