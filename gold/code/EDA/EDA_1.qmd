---
title: "Forecasting Gold-ETF Prices with Gaussian Processes"
author: ""
format: html
bibliography: references.bib
csl: apa.csl # keeps citations consistent
execute:
  echo: true
  warning: false
  error: false
editor: 
  markdown: 
    wrap: 72
---

##### Abstract \[ â‰¤300 words \]

##### 1 Introduction

##### 1.1 Motivation

##### 1.2 Research questions & contributions

##### 2 Literature review <!-- your pdf already drafted  -->

##### 2.1 Gaussian Process theory

##### 2.2 GPR in commodity & financial time-series

##### 2.3 Competing methods (ARIMA, GARCHâ€¦)

##### 3 Data

##### 3.1 Gold-ETF & exogenous drivers

##### 3.2 Exploratory analysis

##### 4 Methodology

##### 4.1 Pre-processing & stationarity tests

##### 4.2 Model specification

##### 4.2.1 Kernel families

##### 4.2.2 Hyper-parameter learning

##### 4.3 Benchmark (ARIMA)

##### 4.4 Evaluation metrics

##### 5 Results

##### 5.1 Point forecasts

##### 5.2 Uncertainty intervals

##### 5.3 Rolling-window comparison

##### 5.4 Discussion

##### 6 Conclusion & future work

```{r}
# General
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(lubridate)

# Timeâ€‘series & ARIMA
library(forecast)
library(tseries)

# Gaussian Processes
library(kernlab)

# Bayesian GP via Stan (optional)
library(cmdstanr)
library(tidyverse)
library(lubridate)
library(forecast)
library(tseries)
library(kernlab)
library(Metrics)
```

### 1. Data loading & initial inspection

We start by importing the full Gold-ETF dataset, parsing the Date column
as an R Date object, sorting chronologically, and quickly checking for
missing values

```{r}
gold <- read_csv("FINAL_USO.csv") %>%
  mutate(
    Date = ymd(Date)
  ) %>%
  arrange(Date)
glimpse(gold)
summary(gold$Close)
sum(is.na(gold))
```

if sum(is.na(.)) \> 0, decide whether to drop, impute, or carry-forward.
Since markets donâ€™t trade on weekends/holidays, you may not need to
impute gaps in Close (Dickey & Fuller, 1979; Kwiatkowski et al., 1992).

Here we quantify calendar days with no trading data. Weekends and public
holidays will show upâ€”but these are expected.

### 2. missing-days analysis

```{r}
# 2.1 Missing trading days
all_days <- seq(min(gold$Date), max(gold$Date), by="day")
missing <- setdiff(all_days, gold$Date)
length(missing)  # how many
```

side note: consider using the timeDate or bizdays package to generate a
trading calendar instead of imputing

### 3. One-year subset & time index

To focus on recent dynamics, we extract the last 252 trading days (â‰ˆ1
year) and create a numeric time index t for our kernels.

```{r}
# One-year subset
end_d <- max(gold$Date)
start_d <- end_d - years(1)
gold1yr <- gold %>% filter(Date >= start_d)

#Time index
gold1yr <- gold1yr %>%
  mutate(t = as.numeric(Date - start_d), 
         price = .data[["Close"]])

# summary of our window
tibble(
  close_column = "Close",
  start_date   = min(gold1yr$Date),
  end_date     = max(gold1yr$Date),
  n_rows       = nrow(gold1yr)
)
library(ggplot2)
ggplot(gold1yr, aes(Date, Close)) +
  geom_line(color="goldenrod") +
  labs(title="Gold Closing Price (One Year)", x="Date", y="Close")

```

visualise the raw price distribution over our one-year window. Figure X
shows that closing prices, with a slight rightâ€skew and a hint of
multiâ€modality (reflecting periods of relative calm punctuated by price
run-ups)

```{r}
ggplot(gold1yr, aes(Close)) +
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30,
                 fill = "skyblue", alpha = 0.6) +
  geom_density(color = "darkblue", size = 1) +
  labs(
    title = "Distribution of Closing Prices",
    x     = "Close (USD/oz)",
    y     = "Density"
  ) +
  theme_minimal()

```

Because this price series is clearly non-stationary (trending upward)
and exhibits heteroskedasticity (variance increasing with level), we
apply a log-transform and then difference to stabilise both the mean and
the variance.

```{r}
# 1. Histogram + QQâ€“plot
ggplot(na.omit(gold1yr), aes(x = logret)) +
  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = "lightblue", alpha=0.6) +
  geom_density(color="darkblue") +
  labs(title="Log-Return Distribution", x="logret", y="Density") +
  theme_minimal()

# QQ-plot
qqnorm(na.omit(gold1yr$logret), main="QQ-Plot of Gold Log-Returns")
qqline(na.omit(gold1yr$logret), col="red")

##arima with trend 
##GLM log(u)=XB + gaussian 


```

### 4. Stationarity & log-returns 

In this chunk we prepare our target series and verify its stationarity
before fitting any timeâ€series mode. We do the following:

-   Variable creation: price is the raw closing price.

-   logret is the daily logâ€return, logret ğ‘¡ = ln â¡ ( Close ğ‘¡ ) âˆ’ ln â¡ (
    Close ğ‘¡ âˆ’ 1 ) , which removes trend and often yields a stationary
    series [@Rasmussen2006].

Augmented Dickeyâ€“Fuller (ADF) tests We test both price and logret for a
unit root. The ADF testâ€™s null hypothesis is that the series is
nonâ€stationary with a unit root [@Dickey1979].

```{r}
gold <- read_csv("FINAL_USO.csv", show_col_types = FALSE) %>%
  mutate(Date = ymd(Date)) %>%
  arrange(Date)

end_d   <- max(gold$Date)
start_d <- end_d - years(1)
gold1yr <- gold %>%
  filter(Date >= start_d) %>%
  mutate(price = Close,
         logret = c(NA, diff(log(Close))))

# â”€â”€ Stationarity tests â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
p_adf <- adf.test(na.omit(gold1yr$price),  k = 0)
r_adf <- adf.test(na.omit(gold1yr$logret), k = 0)

cat("Price ADF p-value:     ", p_adf$p.value, "\n",  # >0.05 â†’ levels non-stationary
    "Log-return ADF p-value:", r_adf$p.value, "\n")  # <0.05 â†’ returns stationary

```

Price levels: ADF p â‰ˆ 0.93 â‡’ fail to reject a unit root â†’
nonâ€stationary.

Logâ€returns: ADF p â‰ˆ 0.01 â‡’ reject a unit root at the 5 % level â†’
(weakly) stationary.

By modelling the stationary logret series, we satisfy the key assumption
of Gaussian Processes (and ARIMA/GARCH) that the target is stable over
time, leading to more robust hyperâ€parameter estimation and forecasting
performance [@AndradeGaleano2021; @Rasmussen2006].

### 5. Visualize & quantify short-memory structure

To decide how much past dependence to encode in our models, we examine
the autocorrelation (ACF) and partial autocorrelation (PACF) of the
daily log-returns. Financial returns typically exhibit at most a
single-lag memory, guiding whether we need an AR(1) mean function or can
assume zero mean in our Gaussian Process.

```{r}
# Extract stationary target
ret <- na.omit(gold1yr$Close)

# Plot ACF & PACF to see how many lags matter
par(mfrow = c(1,2))
acf(ret,  main = "ACF of Gold Log-Returns")
pacf(ret, main = "PACF of Gold Log-Returns")
par(mfrow = c(1,1))

```

if you see a significant spike at lag 1 in the ACF/PACF (which you
typically do for financial returns), you might include a simple AR(1)
mean function inside your GP or note that most serial dependence is very
short-lived (Andrade & Galeano, 2021).

Both the ACF and PACF show a single significant spike at lag 1, with
autocorrelations decaying to zero thereafter. This confirms that
`logret` is a short-memory processâ€”well captured by an AR(1) or even a
zero-mean model, freeing the GP covariance kernel to focus on non-linear
and multi-scale structure \[\@BoxJenkins1976; \@AndradeGaleano2021\].

### 6. Exogenousâ€Driver Correlations

Having confirmed that gold log-returns are a short-memory, stationary
series, we now ask: which macro-financial covariates move in tandem with
these returns? Identifying those with nonâ€trivial correlation helps us
decide which exogenous inputs to feed into our Gaussian Process.

```{r}
# 6.a.)log-returns for each exogenous variable 
exog_close <- c("SP_close", "DJ_close", "EU_Price", "USO_Close", "GDX_Close")

driver_rets <- gold1yr %>%
  select(Date, all_of(exog_close)) %>%
  # apply diff(log(.)) down each column
  mutate(across(-Date, ~ c(NA, diff(log(.))), 
                .names = "{.col}_ret")) %>%
  select(Date, ends_with("_ret")) %>%
  drop_na()   # remove NA row ->1st row 
```

\*Now `driver_rets` holds daily logâ€returns of S&P 500, Dow Jones,
EUR/USD, USO, GDX.\*

```{r}
# 6.b.) Correlate Gold Returns with Driver Returns
# 1. Build a single data.frame with aligned rows
df_corr_rets <- gold1yr %>%
  select(Date, logret) %>%
  inner_join(driver_rets, by="Date") %>%
  select(-Date)

# 2. Compute the correlation matrix
corr_mat_rets <- cor(df_corr_rets, use = "complete.obs")

# 3. Visualize
corrplot(corr_mat_rets,
         method   = "number",
         type     = "upper",
         tl.col   = "black",
         cl.pos   = "n",
         main     = "Corr(log-returns, driver log-returns)")

```

The strongest coâ€movement is between gold and the Gold Miners ETF
(`GDX_Close_ret`), with r â‰ˆ 0.80â€”reflecting minersâ€™ sensitivity to
spotâ€gold shifts.

The EURâ€“USD return (`EU_Price_ret`) also shows a substantial positive
link (r â‰ˆ 0.55), indicating that dollar weakness tends to lift gold.

Although the S&P 500 and Dow Jones log-returns are almost perfectly
correlated with each other, they exhibit virtually no relationship with
gold (\|r\| \< 0.05), and crude-oil returns (`USO_Close_ret`) contribute
only a weak signal (r â‰ˆ 0.09)

Accordingly, we choose `GDX_Close_ret` and `EU_Price_ret` (and, if
desired, `USO_Close_ret` for a small oilâ€price effect) as exogenous
inputs in our Gaussianâ€Process model.

## point estimate GP (via kernlab?)

### 7 Model specification & fitting

Having settled on gold logâ€returns as our stationary target and selected
the top exogenous covariates, we now specify a composite
Gaussianâ€Process (GP) kernel to capture both smooth trends and rough
shocks, plus measurement noise \[\@Rasmussen2006\].

## 7.1 What weâ€™re doing

We now move from a â€œpoint-estimateâ€ Gaussian Process (via `kernlab`) to
a fully Bayesian GP in Stan. This allows us to infer all kernel
hyper-parameters jointly with the noise scale, quantify posterior
uncertainty over each, and propagate that into our forecast intervals.

### Key ingredients

1.  **Data**
    -   **Inputs**:\
        \[ \mathbf{x}\_i =
        \bigl[t_i,\;\mathrm{EU\_Price\_ret}_i,\;\mathrm{GDX\_Close\_ret}_i\bigr].
        \]\
    -   **Target**:\
        \[ y_i = \log(P_i) -
        \log(P\_{i-1})\quad(\text{gold log-return}). \]\
    -   **Reason**: we include the time index (t_i) to capture any
        residual temporal structure, and the two driver returns because
        they exhibited the highest stationary correlations with gold
        returns (râ‰ˆ0.55 and râ‰ˆ0.80) in Section 6.
2.  **Kernel**\
    We use an additive kernel\
    \[ k(\mathbf{x},\mathbf{x}') = k\_{\rm SE}(\mathbf{x},\mathbf{x}')
    -   k\_{\rm M32}(\mathbf{x},\mathbf{x}')
    -   k\_{\rm WN}(\mathbf{x},\mathbf{x}'),, \]\
        where\
    -   (k\_{\rm SE}) (squared-exponential) captures smooth, multi-week
        trends [@Rasmussen2006 Â§4.2; @BrunoDias2018].\
    -   (k\_{\rm M32}) (MatÃ©rn 3/2) captures jagged, day-to-day shocks
        [@Rasmussen2006 Â§4.6; @AndradeGaleano2021].\
    -   (k\_{\rm WN}) (white-noise) absorbs observation-level noise
        [@Rasmussen2006 Â§2.2].

By additive composition, each kernel component cleanly attributes
variance to different timescales. The model can automatically allocate
more weight to the SE part in calm markets or to the MatÃ©rn part during
volatile episodes (marginal likelihood optimization \[\@Rasmussen2006,
Ch.5\]).

**Uncertainty quantification**\
Including an explicit nugget term lets us estimate a noise variance
 sigma^2 , reflecting true observational uncertainty in our posterior
predictive intervals.

1.  **Model**\
    We place a zero-mean GP prior on the latent function and Gaussian
    noise on observations:

k(x,xâ€²) = k\_{\rm SE}(x,xâ€²) + k\_{\rm M32}(x,xâ€²) + k\_{\rm WN}(x,xâ€²)

### 8 Benchmarking with ARIMA

*To gauge the GPâ€™s relative performance, we fit an ARIMA model to the
same logâ€return series and compare pointâ€forecast accuracy.*

########DRAFT BELOW#################

```{r}
# Stationarity checks: price vs. log returns
p_adf  <- try(adf.test(na.omit(gold1yr$price)),  silent = TRUE)
p_kpss <- try(kpss.test(na.omit(gold1yr$price)), silent = TRUE)
r_adf  <- try(adf.test(na.omit(gold1yr$logret)),  silent = TRUE)
r_kpss <- try(kpss.test(na.omit(gold1yr$logret)), silent = TRUE)

cat("\nPrice ADF:\n");  print(p_adf)
cat("\nPrice KPSS:\n"); print(p_kpss)
cat("\nLog-Return ADF:\n");  print(r_adf)
cat("\nLog-Return KPSS:\n"); print(r_kpss)

```

3.  Exploratory Data Analysis 3.1 Closing Price over Time

```{r}
gold <- read_csv("FINAL_USO.csv") %>%
  mutate(
    Date = ymd(Date)
  ) %>%
  arrange(Date)
head(gold)
glimpse(gold)
summary(gold$Close)



# 2. Create log-returns and one-year subset
end_date <- max(gold$Date)
start_date <- end_date - years(1)

gold_year <- gold %>%
  filter(Date >= start_date) %>%
  mutate(
    logReturn = c(NA, diff(log(Close))),
    t_year    = as.numeric(Date - start_date)
  )
glimpse(gold)
# Convert and sort
gold <- gold %>%
  mutate(Date = ymd(Date)) %>%
  arrange(Date)

# Create numeric time index
gold <- gold %>%
  mutate(t = as.numeric(Date - min(Date)))

#scale explanatory variables 

exog_close <- c("SP_close", "DJ_close", "EG_close", "GDX_Close", "USO_Close", "EU_Price")

names(gold)


```

```{r}
# Summary stats
summary_df <- tibble(
  start_date = min(gold1yr$Date),
  end_date   = max(gold1yr$Date),
  n_days     = nrow(gold1yr),
  mean       = mean(gold1yr$price, na.rm = TRUE),
  sd         = sd(gold1yr$price,   na.rm = TRUE),
  min        = min(gold1yr$price,  na.rm = TRUE),
  q25        = quantile(gold1yr$price, 0.25, na.rm = TRUE),
  median     = median(gold1yr$price,    na.rm = TRUE),
  q75        = quantile(gold1yr$price, 0.75, na.rm = TRUE),
  max        = max(gold1yr$price,  na.rm = TRUE)
)
summary_df


# Missing calendar days (informational only; markets don't trade every day)
all_days <- seq(min(gold1yr$Date), max(gold1yr$Date), by = "day")
missing_calendar_days <- setdiff(all_days, gold1yr$Date)
length(missing_calendar_days)

```

3.2 Distribution of Close

```{r}
ggplot(gold1yr, aes(Close)) +
  geom_histogram(aes(y=after_stat(density)), bins=30, fill="skyblue", alpha=0.6) +
  geom_density(color="darkblue") +
  labs(title="Distribution of Closing Prices", x="Close", y="Density")

```

EDA

```{r}
ggplot(gold, aes(Date, Close)) +
  geom_line() +
  labs(
    title = "Daily Gold Closing Price",
    x = "Date", y = "Close (USD/oz)"
  )
```

```{r}
gold <- read_csv("FINAL_USO.csv") %>%
  mutate(
    Date = ymd(Date)
  ) %>%
  arrange(Date)
# Identify and report missing trading days
dates_full <- seq(min(gold$Date), max(gold$Date), by = "day")
missing_dates <- setdiff(dates_full, gold$Date)
message("Missing trading days: ", length(missing_dates))

# 2. Create log-returns and one-year subset
end_date <- max(gold$Date)
start_date <- end_date - years(1)

gold_year <- gold %>%
  filter(Date >= start_date) %>%
  mutate(
    logReturn = c(NA, diff(log(Close))),
    t_year    = as.numeric(Date - start_date)
  )

```

```{r}
# Plot of the one-year closing price
ggplot(gold_year, aes(Date, Close)) +
  geom_line() +
  labs(
    title = "Gold Closing Price: Last One-Year",
    x = "Date", y = "Close (USD/oz)"
  ) +
  theme_minimal()
```

```{r}
# Compute daily log-returns
gold <- gold %>%
  arrange(Date) %>%
  mutate(logReturn = c(NA, diff(log(Close))))

# Histogram with density and normal overlay
g <- ggplot(gold, aes(x = logReturn)) +
  geom_histogram(aes(y = ..density..), bins = 50, fill = "lightblue", alpha = 0.6) +
  geom_density(color = "darkblue") +
  stat_function(
    fun = dnorm,
    args = list(
      mean = mean(na.omit(gold$logReturn)),
      sd   = sd(na.omit(gold$logReturn))
    ),
    color = "red", linetype = "dashed"
  ) +
  labs(
    title = "Distribution of Daily Log-Returns",
    x = "Log-Return", y = "Density"
  ) +
  theme_minimal()
print(g)
```

```{r}
tseries::jarque.bera.test(na.omit(gold$logReturn))
```

Auto-correlation Analysis

```{r}
# ACF and PACF of log-returns
gold_ret <- na.omit(gold$logReturn)
par(mfrow = c(1,2))
acf(gold_ret, main = "ACF of Log-Returns")
pacf(gold_ret, main = "PACF of Log-Returns")
par(mfrow = c(1,1))
```

```{r}
# Correlation among price, volume, and returns
gold %>%
  select(Open, High, Low, Close, Volume, logReturn) %>%
  cor(use = "complete.obs") %>%
  corrplot(method = "number", type = "lower")

names(gold)
```

```{r}
# 
corr_vars <- c("Close", exog_close)

#  correlation matrix
corr_mat <- gold1yr %>%
  select(all_of(corr_vars)) %>%
  cor(use = "complete.obs")


library(corrplot)
corrplot(
  corr_mat,
  method = "number",    
  type   = "upper",     
  tl.cex = 0.8,         
  number.cex = 0.9,     
  col = colorRampPalette(c("red", "white", "blue"))(200)
)
```

```{r}
# single data.frame with aligned rows
df_corr_rets <- gold1yr %>%
  select(Date, logret) %>%
  inner_join(driver_rets, by="Date") %>%
  select(-Date)

#  Compute the correlation matrix
corr_mat_rets <- cor(df_corr_rets, use = "complete.obs")

# Visualize
corrplot(corr_mat_rets,
         method   = "number",
         type     = "upper",
         tl.col   = "black",
         cl.pos   = "n",
         main     = "Corr(log-returns, driver log-returns)")
# â”€â”€ Define your driver columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
exog_close <- c("SP_close", "DJ_close", "EU_Price",
                "USO_Close", "GDX_Close")

# â”€â”€  Build a correlation data frame â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_corr <- gold1yr %>%
  select(logret, all_of(exog_close)) %>%  # logret + drivers
  drop_na()                               

# â”€â”€ Compute the correlation matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
corr_mat <- cor(df_corr, use = "complete.obs")


corrplot(
  corr_mat,
  method   = "number",
  type     = "upper",
  tl.cex   = 0.8,
  number.cex = 0.9,
  col      = colorRampPalette(c("red","white","blue"))(200),
  title    = "Corr(log-returns, drivers)"
)

```

Now `driver_rets` holds daily logâ€returns of S&P 500, Dow Jones,
EUR/USD, USO, GDX.

```{r}


# exogenous variables
exog_close <- c("SP_close", "DJ_close", "EU_Price", "USO_Close", "GDX_Close")

driver_rets <- gold1yr %>%
  select(Date, all_of(exog_close)) %>%
  # apply diff(log(.)) down each column
  mutate(across(-Date, ~ c(NA, diff(log(.))), 
                .names = "{.col}_ret")) %>%
  select(Date, ends_with("_ret")) %>%
  drop_na()   # drop the first NA row

# Build a single data.frame with aligned rows
df_corr_rets <- gold1yr %>%
  select(Date, logret) %>%
  inner_join(driver_rets, by="Date") %>%
  select(-Date)

#correlation analysis 
corr_mat_rets <- cor(df_corr_rets, use = "complete.obs")

corrplot(corr_mat_rets,
         method   = "number",
         type     = "upper",
         tl.col   = "black",
         cl.pos   = "n",
         main     = "Corr(log-returns, driver log-returns)")

```
