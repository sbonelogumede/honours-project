---
title: "Skeleton"
format: html
---

1. Simulate AR(1) with Burn-in
```{r}
# =============================
# Simulate AR(1) process
# =============================

set.seed(123)

n <- 300                # length of series
phi <- 0.7              # AR(1) coefficient
sigma <- 1              # innovation variance

x <- numeric(n)
x[1] <- rnorm(1, 0, sigma)   # initial value
for (t in 2:n) {
  x[t] <- phi * x[t-1] + rnorm(1, 0, sigma)
}

# put into a data frame
ts_data <- data.frame(
  time = 1:n,
  value = x
)

library(ggplot2)
ggplot(ts_data, aes(time, value)) +
  geom_line(color = "brown") +
  theme_minimal() +
  labs(title = "Simulated AR(1) Process",
       x = "Time", y = "Value")

```

```{r}
library(rstan)

set.seed(123)
N <- 100
phi <- 0.8 #autoregression coef
sigma_eps <- 1 #noise 
y <- numeric(N)
y[1] <- rnorm(1, 0, sigma_eps / sqrt(1 - phi^2))
for (t in 2:N) { #AR sequence 
  y[t] <- phi * y[t-1] + rnorm(1, 0, sigma_eps)
}
x <- 1:N

```

Fit GP model 

```{r}
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
cmdstanr::install_cmdstan()


```
```{r}
library(cmdstanr)
mod <- cmdstan_model("gp_rbf_linearmean.stan")
fit <- mod$sample(data = stan_data, chains = 4, iter_warmup = 1000, iter_sampling = 1000, seed = 123)

```


```{r}
stan_data <- list(
  N = N,
  x = as.vector(x),
  y = as.vector(y)
)

fit_gp <- stan(
  file = "gp_se_1d.stan",
  data = stan_data,
  chains = 4,
  iter = 2000,
  seed = 123
)

print(fit_gp, pars = c("beta0","beta1","alpha","rho","sigma"))


```

4. Forecast h steps Ahead 
We compute GP posterior predictive mean & covariance for future points.
```{r}
library(MASS)

h <- 20
x_new <- (N+1):(N+h)

# Extract posterior draws
post <- extract(fit)
alpha <- mean(post$alpha)
rho   <- mean(post$rho)
sigma <- mean(post$sigma)

# Build covariance matrices
K <- outer(x, x, function(a,b) alpha^2 * exp(-abs(a-b)/rho))
diag(K) <- diag(K) + sigma^2

K_star <- outer(x_new, x, function(a,b) alpha^2 * exp(-abs(a-b)/rho))
K_starstar <- outer(x_new, x_new, function(a,b) alpha^2 * exp(-abs(a-b)/rho))

# Predictive mean & covariance
K_inv <- solve(K)
mu_star <- K_star %*% K_inv %*% y
Sigma_star <- K_starstar - K_star %*% K_inv %*% t(K_star)

# Draw samples from predictive distribution
y_pred <- mvrnorm(50, mu = mu_star, Sigma = Sigma_star)

```

5. plot forecast 
```{r}
matplot(x_new, t(y_pred), type="l", col=rgb(0.6,0.2,0.2,0.2),
        lty=1, xlab="Time", ylab="Forecast", main="GP Forecast with Exponential Kernel")
lines(x, y, col="black")
lines(x_new, mu_star, col="blue", lwd=2)

# Compute pointwise credible intervals across sample paths
forecast_lower <- apply(y_pred, 2, quantile, probs = 0.025)
forecast_upper <- apply(y_pred, 2, quantile, probs = 0.975)

# Plot sample paths
matplot(x_new, t(y_pred), type="l", col=rgb(0.6,0.2,0.2,0.2),
        lty=1, xlab="Time", ylab="Forecast", 
        main="GP Forecast with Exponential Kernel")

# Historical data
lines(x, y, col="black")

# Posterior mean
lines(x_new, mu_star, col="blue", lwd=2)

# Add 95% credible interval as shaded band
polygon(c(x_new, rev(x_new)),
        c(forecast_lower, rev(forecast_upper)),
        col = rgb(0.1, 0.1, 0.9, 0.2), border = NA)

# Re-draw mean forecast on top so it's not hidden
lines(x_new, mu_star, col="blue", lwd=2)


```
-horizontal axis (Time) goes beyond your observed series (after 100), so it covers the forecast horizon (up to 120 here)

-vertical axis (Forecast) is the value of the predicted series.

-blue line is the posterior mean forecast (the expected value predicted by the GP).


-thin brown lines are posterior sample paths from the GP — they represent possible realizations of the future according to the model, showing the uncertainty.

Interpretation: 
The forecasts “decay” back towards zero (the GP’s prior mean) as the forecast horizon increases — this is typical of an exponential kernel, which assumes short-range dependence

-Shaded purple region → 95% credible interval, showing the uncertainty around the forecast at each future time point

The further ahead you go, the wider the spread of sample paths, reflecting increasing uncertainty in the forecast.

Unlike an AR(1) which has a specific autoregressive structure, the GP exponential kernel is more flexible but also tends to revert quickly to the mean (here ≈ 0).



6. Fit AR(1) process model to AR(1) simulation and then comapre with GP forecast 
```{r}
library(forecast)

# Assume y is your simulated AR(1) time series
# Fit an AR model using AIC to select order
fit_ar <- Arima(y, order=c(1,0,0))  # AR(1) explicitly
summary(fit_ar)

# Forecast h steps ahead
h <- 20
ar_forecast <- forecast(fit_ar, h=h)

# Plot AR forecast
plot(ar_forecast, main="AR(1) Forecast on Simulated Data")
lines(y, col="black")

#blue mean forecast and grey prediction intervals.

```


```{r}
# Compute GP credible intervals pointwise across samples
gp_lower <- apply(y_pred, 2, quantile, 0.025, na.rm = TRUE)
gp_upper <- apply(y_pred, 2, quantile, 0.975, na.rm = TRUE)

x_new <- 101:120   # match AR(1) horizon

# Overlay AR(1) and GP forecasts
plot(y, type="l", col="black", xlim=c(0, 120),
     ylim=range(c(y, ar_forecast$mean, mu_star, gp_lower, gp_upper)),
     xlab="Time", ylab="Value", main="AR(1) vs GP Forecast")

# AR forecast (blue line with CI)
lines(101:120, ar_forecast$mean, col="blue", lwd=2)
lines(101:120, ar_forecast$lower[,2], col="blue", lty=2)
lines(101:120, ar_forecast$upper[,2], col="blue", lty=2)

# GP forecast (red line with shaded CI)
lines(x_new, mu_star, col="red", lwd=2)
polygon(c(x_new, rev(x_new)),
        c(gp_lower, rev(gp_upper)),
        col=rgb(1,0,0,0.2), border=NA)
lines(x_new, gp_lower, col="red", lty=2)
lines(x_new, gp_upper, col="red", lty=2)

# Legend
legend("topleft", legend=c("Data", "AR(1)", "GP"),
       col=c("black","blue","red"), lwd=2, lty=1, bty="n")



```
=> figure out difference in lines 

Point Forecast Accuracy (RMSE / MAE)
```{r}
# =============================
# Numeric Comparison of AR(1) vs GP
# =============================

# True future values (from the AR(1) simulation)
y_true <- y[101:120]

# --- AR(1) ---
ar_mean <- as.numeric(ar_forecast$mean)

ar_rmse <- sqrt(mean((y_true - ar_mean)^2))
ar_mae  <- mean(abs(y_true - ar_mean))

# --- GP ---
gp_mean <- as.numeric(mu_star)  # posterior mean forecast

gp_rmse <- sqrt(mean((y_true - gp_mean)^2))
gp_mae  <- mean(abs(y_true - gp_mean))

# Print results
cat("AR(1) RMSE:", ar_rmse, "\n")
cat("AR(1) MAE :", ar_mae, "\n")
cat("GP   RMSE:", gp_rmse, "\n")
cat("GP   MAE :", gp_mae, "\n")

```
```{r}
# Train-test split
train <- y[1:80]
test  <- y[81:100]   # true future values

# Fit AR(1) on training
fit_ar <- Arima(train, order=c(1,0,0))
ar_forecast <- forecast(fit_ar, h=20)

# Prepare GP data (fit only on training part)
stan_data <- list(
  N = length(train),
  x = 1:length(train),
  y = as.vector(train)
)
fit <- stan(file="gp_se_1d.stan", data=stan_data, 
            chains=4, iter=2000, warmup=1000, seed=123)

post <- extract(fit)
alpha <- mean(post$alpha); rho <- mean(post$rho); sigma <- mean(post$sigma)

# Predict with GP on test horizon
x_train <- 1:length(train)
x_new   <- (length(train)+1):(length(train)+20)

K <- outer(x_train, x_train, function(a,b) alpha^2 * exp(-abs(a-b)/rho))
diag(K) <- diag(K) + sigma^2
K_star <- outer(x_new, x_train, function(a,b) alpha^2 * exp(-abs(a-b)/rho))
K_starstar <- outer(x_new, x_new, function(a,b) alpha^2 * exp(-abs(a-b)/rho))

K_inv <- solve(K)
mu_star <- K_star %*% K_inv %*% train
Sigma_star <- K_starstar - K_star %*% K_inv %*% t(K_star)

# Compare with test values
y_pred_gp <- mu_star

# Error metrics
library(Metrics)
ar_rmse <- rmse(test, ar_forecast$mean)
ar_mae  <- mae(test, ar_forecast$mean)

gp_rmse <- rmse(test, y_pred_gp)
gp_mae  <- mae(test, y_pred_gp)

cat("AR(1) RMSE:", ar_rmse, "\n")
cat("AR(1) MAE :", ar_mae, "\n")
cat("GP   RMSE:", gp_rmse, "\n")
cat("GP   MAE :", gp_mae, "\n")

```

Both models are very close in performance on this dataset.

AR(1) edges out slightly (lower RMSE and MAE), which makes sense because the true data generating process is AR(1).

The GP, while flexible, has to “learn” structure from the data and doesn’t assume AR dependence directly, so it does almost as well but not better.

If you were to simulate from something nonlinear or with different dependence (say ARMA, or periodic), can the GP potentially outperform AR(1)?

--> mean percentage error (MAPE=>% var)

Add ddotted lines for comparison 



```{r}
#AR simulation 
set.seed(42)
n <- 60
phi <- 0.8
sigma <- 1
x <- numeric(n)
eps <- rnorm(n, 0, sigma)
for (t in 2:n) {
  x[t] <- phi * x[t-1] + eps[t]
}
time <- 1:n
# ---- fit AR(1) ----
fit_ar <- arima(x, order = c(1,0,0))
ar_forecast <- forecast(fit_ar, h=20)
```


```{r}
# ---- GP fit with Stan ----
stan_data <- list(
  N = n,
  N_pred = n+20,
  x = time,
  y = x,
  x_pred = 1:(n+20)
)

fit_gp <- stan(file="gp_regression.stan", data=stan_data,
               iter=2000, chains=4)

post <- rstan::extract(fit_gp)

# posterior predictive mean and sd
gp_mean <- apply(post$f_mean, 2, mean)
gp_sd   <- apply(sqrt(matrix(unlist(post$f_cov), nrow=stan_data$N_pred)), 2, mean)

df_gp <- data.frame(
  time = 1:(n+20),
  mean = gp_mean,
  lower = gp_mean - 2*gp_sd,
  upper = gp_mean + 2*gp_sd
)

df_ar <- data.frame(
  time = (n+1):(n+20),
  mean = as.numeric(ar_forecast$mean),
  lower = as.numeric(ar_forecast$lower[,2]),
  upper = as.numeric(ar_forecast$upper[,2])
)

```
```{r}
ggplot() +
  geom_point(aes(x=time, y=x), color="black") +
  geom_line(aes(x=2:n, y=fitted(fit_ar)), color="red") +
  geom_line(aes(x=time, y=mean), color="blue", data=df_gp) +
  geom_ribbon(aes(x=time, ymin=lower, ymax=upper), fill="blue", alpha=0.2, data=df_gp) +
  geom_line(aes(x=time, y=mean), color="red", linetype="dashed", data=df_ar) +
  geom_ribbon(aes(x=time, ymin=lower, ymax=upper), fill="red", alpha=0.2, data=df_ar) +
  geom_vline(xintercept=n, linetype="dashed", color="gray") +
  labs(title="AR(1) vs Gaussian Process: Fitted Values & Forecasts",
       x="Time", y="Value") +
  theme_minimal()
```
mmmmmmm
```{r}
set.seed(42)

# Parameters
n <- 60
phi <- 0.8
sigma <- 1

# Simulate AR(1)
y <- numeric(n)
y[1] <- rnorm(1, 0, sigma / sqrt(1 - phi^2))
for (t in 2:n) {
  y[t] <- phi * y[t-1] + rnorm(1, 0, sigma)
}

x <- 1:n  # time

#fit AR and forecast 
library(forecast)

fit_ar <- Arima(y, order = c(1,0,0))
ar_forecast <- forecast(fit_ar, h = 20)

# Extract fitted values and forecast
y_fit_ar <- fitted(fit_ar)
ar_mean <- as.numeric(ar_forecast$mean)
ar_lower <- as.numeric(ar_forecast$lower[, 2])
ar_upper <- as.numeric(ar_forecast$upper[, 2])

```

```{r}
library(cmdstanr)
library(posterior)

# Standardize inputs
x_std <- scale(x)[,1]

# Prepare data
stan_data <- list(
  N = n,
  x = x_std,
  y = y
)

# Compile and sample
mod <- cmdstan_model("gp_rbf_linearmean.stan")
fit <- mod$sample(data = stan_data, chains = 4, iter_sampling = 1000, iter_warmup = 1000)

# Extract posterior means
draws <- fit$draws(variables = c("beta0", "beta1", "alpha", "rho", "sigma"))
params <- summarise_draws(draws)

beta0 <- params$mean[1]
beta1 <- params$mean[2]
alpha <- params$mean[3]
rho   <- params$mean[4]
sigma <- params$mean[5]

```

```{r}
#GP Forecast Using Posterior Mean
library(MASS)
post <- extract(fit)
str(post)  # inspect it


h <- 20
x_new <- (n+1):(n+h)
x_all <- c(x, x_new)
x_all_std <- scale(x_all)[,1]
x_std_new <- x_all_std[(n+1):(n+h)]

# Build matrices
K <- outer(x_std, x_std, function(a,b) alpha^2 * exp(-0.5 * (a - b)^2 / rho^2))
diag(K) <- diag(K) + sigma^2

K_star <- outer(x_std_new, x_std, function(a,b) alpha^2 * exp(-0.5 * (a - b)^2 / rho^2))
K_starstar <- outer(x_std_new, x_std_new, function(a,b) alpha^2 * exp(-0.5 * (a - b)^2 / rho^2))

K_inv <- solve(K)

# Mean and variance
mu <- beta0 + beta1 * x_std
mu_star <- beta0 + beta1 * x_std_new + K_star %*% K_inv %*% (y - mu)
Sigma_star <- K_starstar - K_star %*% K_inv %*% t(K_star)

# 95% CI
gp_lower <- mu_star - 2 * sqrt(diag(Sigma_star))
gp_upper <- mu_star + 2 * sqrt(diag(Sigma_star))

```
```{r}
plot(y, type = "p", col = "black", xlim = c(0, n + h), ylim = range(c(y, mu_star, ar_upper, gp_upper)),
     xlab = "Time", ylab = "Value", main = "AR(1) vs GP Forecast")

# AR(1)
lines(1:n, y_fit_ar, col = "red", lwd = 2)
lines(x_new, ar_mean, col = "red", lty = 2, lwd = 2)
lines(x_new, ar_lower, col = "red", lty = 3)
lines(x_new, ar_upper, col = "red", lty = 3)

# GP
lines(x_new, mu_star, col = "blue", lwd = 2)
polygon(c(x_new, rev(x_new)),
        c(gp_lower, rev(gp_upper)),
        col = rgb(0, 0, 1, 0.2), border = NA)

# Legend
legend("topleft", legend = c("Data", "AR(1)", "GP"),
       col = c("black", "red", "blue"), lty = 1, lwd = 2, bty = "n")

```

```{r}
# y_fit_gp, which is the Gaussian Process posterior mean on the training data (i.e., the GP "fit" to the observed points, not just the forecast).
# 1. Extract posterior means (already done)
alpha <- mean(post$alpha)
rho   <- mean(post$rho)
sigma <- mean(post$sigma)

# 2. Rebuild training kernel (K) using exponential kernel
K <- outer(x, x, function(a,b) alpha^2 * exp(-abs(a-b)/rho))
diag(K) <- diag(K) + sigma^2

# 3. Compute GP fit (posterior mean on training points)
K_inv <- solve(K)
y_fit_gp <- K %*% K_inv %*% y   # or simply: y_fit_gp <- y



```


```{r}

# Assume:
# y: original time series (length n)
# y_fit_ar: fitted values from AR(1)
# ar_forecast: forecast object from forecast::forecast()
# mu_star: GP forecast mean
# gp_lower, gp_upper: GP 95% credible interval bounds
# y_fit_gp: fitted values from GP on training data (posterior mean)
# n: length of training set
# h: forecast horizon

# Combine forecast index
x_forecast <- (n+1):(n+h)

# Plot base with black points
plot(1:n, y, type = "b", col = "black", pch = 10,
     xlim = c(0, n + h), ylim = range(c(y, mu_star, gp_lower, gp_upper)),
     xlab = "Time", ylab = "Value", main = "AR(1) vs GP Forecast")

# Add AR(1) fit and forecast
lines(1:n, y_fit_ar, col = "red", lwd = 2)
lines(x_forecast, ar_forecast$mean, col = "red", lwd = 2, lty = 2)
lines(x_forecast, ar_forecast$lower[,2], col = "red", lty = 3)
lines(x_forecast, ar_forecast$upper[,2], col = "red", lty = 3)

# GP fitted values (training region)
lines(1:n, y_fit_gp, col = "blue", lwd = 2)

# GP forecast with credible band
polygon(c(x_forecast, rev(x_forecast)),
        c(gp_lower, rev(gp_upper)),
        col=rgb(0.1, 0.1, 0.9, 0.2), border=NA)

# GP forecast mean
lines(x_forecast, mu_star, col = "blue", lwd = 2)

# Add legend
legend("bottomleft", legend=c("Data", "AR(1)", "AR(1) 95% CI", "GP", "GP 95% CI"),
       col=c("black", "red", "red", "blue", rgb(0.1, 0.1, 0.9, 0.2)),
       lty=c(NA, 1, 3, 1, NA), lwd=c(NA, 2, 1, 2, NA), pch=c(16, NA, NA, NA, 15),
       pt.cex=c(1, NA, NA, NA, 2), bty = "n")

```

