\documentclass[a4paper, 10pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[justification=centering]{caption}
\usepackage[top=1in, bottom=1in, left=1.25in, right=1in]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{titlesec}

\titleformat{\section}[block]{\normalfont\Large\bfseries\centering}{\thesection}{1em}{}

\title{Gaussian Processes for Time Series}
\date{\today}
\author{Raphaela Azar and Sbonelo Gumede \\
Supervised by Prof. Birgit Erni\\
The University of Cape Town}

\begin{document}

   \maketitle

   \begin{flushleft}

   \section*{Abstract}

    In this paper we hope to define what is a Gaussian process. How can you use a Gaussian process for time series analysis? Compare the peformance of a Gaussian process to other time series analysis models such as state-space models. An area of application included is predicting the level of air pollution in the Table View station in Cape Town for the year of 2019. Another area of application is predicting the gold price for South Africa for the year of 2020. This is done in a Bayesian framework in order to make probabilistic statements and obtain a predictive distribution for future forecasts.

   \newpage

   \section*{Literature Review}

   ((Rasmussen and Williams, 2006)) We have a training set of $\mathcal{D}$ of $n$ observations, $\mathcal{D} = \{(\mathbf{x}_{i}, y_{i}) \, | \, i = 1, \, \ldots, \, n\}$, where $\mathbf{x}$ denotes the input vector (covariates) of dimension $\mathcal{D}$ and y denotes a scalar output or targer (dependent variable); the column vector of inputs for all n cases are arranged in the $\mathcal{D} \times n \, design \, matrix\, X$, and the targets are collected in the vector $\mathbf{y}$, so we can write $\mathcal{D} = (X, \mathbf{y})$. 

   \vspace{1em}

   \textbf{Definition 2.1.1} ((Rasmussen and Williams, 2006)).
   \textit{A Gaussian process is a collection of random variables, any finite number of which have a joint Gaussian distribution.}

   \vspace{1em}

   A Gaussian process is completely specified by its mean function and co-variance function. We define mean mean function $m(\mathbf{x})$ and the covariance function $k(\mathbf{x}, \mathbf{x}')$ for a real process $f(\mathbf{x})$ as
   $$m(\mathbf{x}) = \mathbb{E}[f(\mathbf{x})],$$
   $$k(\mathbf{x}, \mathbf{x}') = \mathbb{E}[(f(\mathbf{x}) - m(\mathbf{x}))(f(\mathbf{x}' - m(\mathbf{x}')))],$$
   and will write the Gaussian process as
   $$f(\mathbf{x}) \sim \text{GP}(m(\mathbf{x}), k(\mathbf{x}, \mathbf{x}')).$$

   $\mathbf{x} =
   \begin{bmatrix}
      X_{1} \\
      \vdots \\
      X_{p}
   \end{bmatrix}
   \:
   \sim \mathcal{N}_{p}(\boldsymbol{\mu}, \, \boldsymbol{\Sigma}),
   \:
   \text{where}
   \:
   \boldsymbol{\mu} = 
   \begin{bmatrix}
      m(x_{1}) \\
      m(x_{2}) \\
      \vdots \\
      m(x_{p})
   \end{bmatrix}  
   \: 
   \text{and}
   \:
   \boldsymbol{\Sigma} = 
   \begin{bmatrix}
      k(x_{1}, \, x_{1}) & k(x_{1}, \, x_{2}) & \cdots & k(x_{1}, \, x_{p}) \\
      k(x_{2}, \, x_{1}) & k(x_{2}, \, x_{2}) & \cdots & k(x_{2}, \, x_{p}) \\
      \vdots & \vdots & \ddots & \vdots \\
      k(x_{p}, \, x_{1}) & k(x_{p}, \, x_{2}) & \cdots & k(x_{p}, \, x_{p})
   \end{bmatrix}$.
   
   \vspace{1em}

   Consider a simple example shown in figure 1, where $m(\mathbf{x}) = \mathbf{x} \, \text{and} \, k(\mathbf{x}, \mathbf{x}') = \text{I}_{p}$. 

   \begin{figure}[H]
      \centering
      \includegraphics[width=0.48\linewidth]{../img/gp.png}
      \caption{\textit{An example of a Gaussian process on $t \in \{0, \, 10, \, \ldots, \, 50\}$.}}
   \end{figure}
   
   Often people use 
   $$m(x_{t}) = 0$$ 
   and 
   $$k(x_{i}, \, x_{j}) = \alpha^{2} \text{exp}(- \frac{1}{2} (\frac{|x_i - x_j|}{\rho})^2) + \sigma\delta_{ij},$$ 
   $$\text{where} \, \delta_{ij} = 1 \, \text{for} \, i = j \, \text{and} \, \delta_{ij} = 0 \, \text{for} \, i \neq j, \, \alpha, \, \rho, \, \text{and} \, \sigma \, \text{are hyperparameters}.$$ 
   The latter is known as the squared-exponential kernel. Some kernel functions common in the literature are the following:

   \newpage 

   \section*{Air pollution example}
   \subsection*{Exploratory data analysis}
   
      \begin{table}[H]
         \centering
         \begin{tabularx}{\textwidth}{|l|l|X|l|}
         \hline
         \text{Variable} & \text{Name} & \text{Description} & \text{Unit} \\
         \hline
         \(\text{NO}_{2}\) & Nitrogen dioxide & A harmful gas from vehicles and industry. & \(\mu\text{g}/\text{m}^{3}\) \\
         \(\text{PM}_{10}\) & Particulate matter 10 & Small inhalable dust particles. & \(\mu\text{g}/\text{m}^{3}\) \\
         \(\text{SO}_{2}\) & Sulphur dioxide & Mainly from burning fossil fuels. & \(\mu\text{g}/\text{m}^{3}\) \\
         Speed & Wind speed & How fast the wind is moving. & m/s \\
         \hline
         \end{tabularx}
         \caption{\textit{Description of variables of the air pollution dataset.}}
         \label{tab:variable_description}
      \end{table}

      \begin{table}[H]
         \centering
         \begin{tabularx}{\textwidth}{|l|X|X|X|X|X|X|X|X|}
            \hline
            Variable & Min. & 1st Qu. & Median & Mean & Std. & 3rd Qu. & Max. & NA's \\
            \hline
            NO$_2$   & 0.0 & 5.0  & 9.0  & 12.73 & 10.72 & 17.0 & 113.0 & 734 \\
            PM$_{10}$ & 0.0 & 12.0 & 17.0 & 19.82 & 12.30 & 24.0 & 158.0 & 298 \\
            SO$_2$   & 0.0 & 2.0  & 3.0  & 6.20  & 11.30 & 5.0  & 142.0 & 638 \\
            Speed    & 0.5 & 2.3  & 3.6  & 3.74  & 1.71  & 4.9  & 11.2  & 918 \\
            \hline
         \end{tabularx}
         \caption{\textit{Summary statistics of the air pollution dataset.}}
         \label{tab:summary_statistics}
      \end{table}

      \begin{figure}[H]
         \centering
         \includegraphics[width=0.48\linewidth]{../img/corrplot.png}
         \caption{\textit{Correlation plot of the air pollution dataset.}}
      \end{figure}

      Our response variable $\text{NO}_{2}$ appears to be moderately positively correlated with $\text{PM}_{10}$ and $\text{SO}_{2}$, and moderately negatively correlated with Speed. These are not ideal explanatory variables since we typically would like them to be strongly correlated with the response variable. The explanatory variables are weekly correlated with one another, whether it be positive or negative correlation. This is ideal since some models do not work well with correlated explanatory variables, often leading to unstable point estimates and inflated standard errors.

      \vspace{1em}

      Before looking at the data. The proposal mean function is $f(x_{t}) = x_{t}^{T} \beta + e$ and the proposal covariance function is $g(x_{i}, x_{j}) = \alpha^{2} \text{exp}(- \frac{1}{2} (\frac{|x_i - x_j|}{\rho})^2) + \sigma\delta_{ij} \, \text{for} \, i,j \in \mathcal{I}$. This allows us to capture the trend (if it exists) in the time series. This also allows us to capture the correlation structure of the data. The squared-exponential kernel is chosen because it is a natural way of describing the correlation decay.

      \vspace{1em}

      The prior distributions of the exponantiated quadratic kernel are the following: $\alpha \sim \text{half-normal}(0, 1)$, $\rho \sim \mathcal{IG}(20, 10)$, and $\sigma \sim \text{half-normal}(0, 1)$.

      \begin{figure}[H]
         \centering
         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/extracted_no2.png}
         \caption{Nitrogen dioxide}
         \end{subfigure}
         \hfill
         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/extracted_pm10.png}
            \caption{Particulate matter 10}
         \end{subfigure}
         
         \vspace{0.5em}

         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/extracted_so2.png}
         \caption{Sulphur dioxide}
         \end{subfigure}
         \hfill
         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/extracted_speed.png}
            \caption{Wind speed}
         \end{subfigure}

         \caption{\textit{Time-series plots of nitrogen dioxide and mereorological processes from 01/01/2018 to 31/12/2019 measured hourly. Similar cyclic patterns can be observed in the meteorological processes, and a weaker seasonality component can be noted in the yearly nitrogen dioxide processes.}}
      \end{figure}

      \begin{figure}[H]
         \centering
         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/transformed_no2.png}
         \caption{Nitrogen dioxide}
         \end{subfigure}
         \hfill
         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/transformed_pm10.png}
            \caption{Particulate matter 10}
         \end{subfigure}
         
         \vspace{0.5em}

         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/transformed_so2.png}
         \caption{Sulphur dioxide}
         \end{subfigure}
         \hfill
         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/transformed_speed.png}
            \caption{Wind speed}
         \end{subfigure}

         \caption{\textit{Post-processed daily curves of the nitrogen dioxide and meteorological data, both standardized by their overall mean and standard deviation.}}
      \end{figure}

      \subsection*{Components of the time series}     

      The response variable time-series $x_{t}$ is not statationary because the mean and variance are changing with time. To achieve stationarity there is a need for detrending and a variance stabilizing transformation. In order to stabilize the variance we use Box-Cox transformations in the training set, $y_{t} = (x_{t}^{\lambda} - 1) / \lambda$. The Box-Cox transformations allow us to experiment with a wide variety of $\lambda$ values. A good value of $\lambda$ is one the makes the variation in the data constant through time (Neil Watson, 2024). The \texttt{R} package \texttt{forecast} was used to perform the Box-Cox transformation which yielded an optimal value of $\hat{\lambda} \approx 0$, suggesting a logarithmic transformation. Then, conducting first-order differencing at lag one to remove the trend $z_{t} = y_{t} - y_{t-1} \, \text{for} \, t \in \{2, \, 3, \, \ldots, \, p\}$. The time series $z_{t}$ is now stationary. Thus, we only need to account for the mean and variance in our models.      

      \begin{figure}[H]
         \centering
         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/extracted_no2.png}
            \caption{Before transformations.}
         \end{subfigure}
         \hfill
         \begin{subfigure}{0.48\linewidth}
            \centering
            \includegraphics[width=\linewidth]{../img/stationary_no2.png}
            \caption{After transformations.}
         \end{subfigure}
         \caption{\textit{Comparison of NO\textsubscript{2} time series before and after transformations.}}
      \end{figure}

      \subsection*{Results}

      \begin{table}[H]
         \centering
         \begin{tabular}{lcccccc}
         \hline
         \multirow{2}{*}{Model} & \multicolumn{3}{c}{RMSE} & \multicolumn{3}{c}{MAE} \\
         \cline{2-7}
         & \multicolumn{3}{c}{Forecasts} & \multicolumn{3}{c}{Forecasts} \\
         & \multicolumn{3}{c}{($h$ day time horizon)} & \multicolumn{3}{c}{($h$ day time horizon)} \\
         & 24 & 168 & 720 & 24 & 168 & 720 \\
         \hline
         Average & 8.61 & 7.16 & 6.62 & 8.54 & 6.48 & 5.73 \\
         \rowcolor{blue!20} Naive & 1.35 & 5.58 & 7.10 & 1.00 & 3.59 & 4.80 \\
         SNaive & 3.72 & 5.71 & 7.21 & 2.48 & 4.05 & 5.28 \\
         Drift & 1.35 & 5.59 & 7.16 & 1.00 & 3.60 & 4.86 \\
         ARIMA & 5.01 & 6.46 & 6.45 & 4.91 & 5.81 & 5.57 \\
         \rowcolor{red!20} GP & 6.07 & 8.73 & 10.72 & 5.47 & 7.29 & 9.14 \\
         \hline
         \end{tabular}
         \caption{\textit{RMSE and MAE of forecasting models across horizons.}}
      \end{table}

   \section*{References}
      \begin{enumerate}
         \item https://www.lung.org/clean-air/outdoors/what-makes-air-unhealthy/nitrogen-dioxide
      \end{enumerate}
   
   \end{flushleft}
\end{document}
